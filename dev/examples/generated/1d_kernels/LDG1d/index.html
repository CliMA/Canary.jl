<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>1D Diffusion Equation Example · Canary.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../../../assets/documenter.js"></script><script src="../../../../siteinfo.js"></script><script src="../../../../../versions.js"></script><link href="../../../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Canary.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../../../">Home</a></li><li><a class="toctext" href="../../../../manual/dg_intro/">Introduction to DG</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../../../../manual/mesh/">Mesh</a></li><li><a class="toctext" href="../../../../manual/metric/">Metric Terms</a></li><li><a class="toctext" href="../../../../manual/operators/">Element Operators</a></li></ul></li><li><span class="toctext">Examples</span><ul><li class="current"><a class="toctext" href>1D Diffusion Equation Example</a><ul class="internal"><li><a class="toctext" href="#Introduction-1">Introduction</a></li><li><a class="toctext" href="#Continuous-Governing-Equations-1">Continuous Governing Equations</a></li><li><a class="toctext" href="#Local-Discontinous-Galerkin-(LDG)-Method-1">Local Discontinous Galerkin (LDG) Method</a></li><li><a class="toctext" href="#Commented-Program-1">Commented Program</a></li></ul></li><li><a class="toctext" href="../burger1d/">1D Burgers Equation</a></li><li><a class="toctext" href="../swe1d/">1D Shallow Water Equations</a></li><li><a class="toctext" href="../../2d_kernels/LDG2d/">2D Diffusion Equation Example</a></li><li><a class="toctext" href="../../2d_kernels/swe2d/">2D Shallow Water Equations</a></li><li><a class="toctext" href="../../2d_kernels/nse2d/">2D Compressible Navier-Stokes Equations</a></li><li><a class="toctext" href="../../3d_kernels/LDG3d/">3D Diffusion Equation Example</a></li><li><a class="toctext" href="../../3d_kernels/nse3d/">3D Compressible Navier-Stokes Equations</a></li></ul></li><li><span class="toctext">API Reference</span><ul><li><a class="toctext" href="../../../../reference/mesh/">Mesh</a></li><li><a class="toctext" href="../../../../reference/metric/">Metric Terms</a></li><li><a class="toctext" href="../../../../reference/operators/">Element Operators</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Examples</li><li><a href>1D Diffusion Equation Example</a></li></ul><a class="edit-page" href="https://github.com/climate-machine/Canary.jl/blob/master/examples/1d_kernels/LDG1d.jl"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>1D Diffusion Equation Example</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="D-Diffusion-Equation-Example-1" href="#D-Diffusion-Equation-Example-1">1D Diffusion Equation Example</a></h1><h2><a class="nav-anchor" id="Introduction-1" href="#Introduction-1">Introduction</a></h2><p>This example shows how to construct a 2nd derivative with DG using LDG.</p><h2><a class="nav-anchor" id="Continuous-Governing-Equations-1" href="#Continuous-Governing-Equations-1">Continuous Governing Equations</a></h2><p>We discretize the operator:</p><div>\[\frac{\partial^2 q}{\partial x^2}  \; \; (1)\]</div><p>in the following two-step process. First we discretize</p><div>\[Q = \frac{\partial q}{\partial x}  \; \; (2)\]</div><p>followed by</p><div>\[\frac{\partial Q}{\partial x} =  \frac{\partial^2 q}{\partial x^2}  \; \; (3)\]</div><h2><a class="nav-anchor" id="Local-Discontinous-Galerkin-(LDG)-Method-1" href="#Local-Discontinous-Galerkin-(LDG)-Method-1">Local Discontinous Galerkin (LDG) Method</a></h2><p>Discretizing Eq. (2) we get</p><div>\[\int_{\Omega_e} \psi {Q}^{(e)}_N d\Omega_e = \int_{\Omega_e} \psi \frac{\partial q^{(e)}_N}{\partial x} d\Omega_e \; \; (4)\]</div><p>where <span>$q^{(e)}_N=\sum_{i=1}^{(N+1)^{dim}} \psi_i(\mathbf{x}) q_i$</span> and  <span>${Q}^{(e)}_N=\sum_{i=1}^{(N+1)^{dim}} \psi_i(\mathbf{x}) {Q}_i$</span> are the finite dimensional expansion with basis functions <span>$\psi(x)$</span>. Integrating Eq. (4) by parts yields</p><div>\[\int_{\Omega_e} \psi {Q}^{(e)}_N d\Omega_e = \left[ \psi q^{(*,e)}_N \right]_{\Gamma_e} - \int_{\Omega_e} \frac{\partial \psi}{\partial x} q^{(e)}_N d\Omega_e \; \; (5)\]</div><p>where the first term on the right denotes the flux integral term (computed in &quot;function fluxQ&quot;) and the second term on the right denotes the volume integral term (computed in &quot;function volumeQ&quot;).  The superscript <span>$(*,e)$</span> in the flux integral term denotes the numerical flux. Here we use the average flux. In matrix form, Eq. (5) becomes</p><div>\[M^{(e)}_{i,j} Q^{(e)}_j = {F}_{i,j} q^{(*,e)}_j - \widetilde{{D}}^{(e)} q^{(e)}_j \; \; (6)\]</div><p>Next, integrating Eq. (3) by parts gives a similar form to Eq. (6) as follows</p><div>\[M^{(e)}_{i,j} \frac{\partial^2 q^{(e)}_j}{\partial x^2} = {F}_{i,j} Q^{(*,e)}_j - \widetilde{{D}}^{(e)} Q^{(e)}_j \; \; (7)\]</div><p>Since we use the average flux for both <span>$q$</span> and <span>$Q$</span>, we can reuse the same functions to construct <span>${F}$</span> and <span>$\widetilde{{D}}$</span> in both Eqs.\ (6) and (7).  However, this will not be the case in multiple dimensions since Eq. (6) represents a gradient operator while Eq. (7) represents a divergence operator.</p><h2><a class="nav-anchor" id="Commented-Program-1" href="#Commented-Program-1">Commented Program</a></h2><div><pre><code class="language-julia">include(joinpath(@__DIR__,&quot;vtk.jl&quot;))
using MPI
using Canary
using Printf: @sprintf
const HAVE_CUDA = try
    using CUDAnative
    using CUDAdrv
    true
catch
    false
end
if HAVE_CUDA
    macro hascuda(ex)
        return :($(esc(ex)))
    end
else
    macro hascuda(ex)
        return :()
    end
end</code></pre><pre><code class="language-none">@hascuda (macro with 1 method)</code></pre></div><p>{{{ reshape for CuArray</p><div><pre><code class="language-julia">@hascuda function Base.reshape(A::CuArray, dims::NTuple{N, Int}) where {N}
    @assert prod(dims) == prod(size(A))
    CuArray{eltype(A), length(dims)}(dims, A.buf)
end</code></pre><pre><code class="language-none">()</code></pre></div><p>}}}</p><p>{{{ constants note the order of the fields below is also assumed in the code.</p><div><pre><code class="language-julia">const _nstate = 2
const _U, _h = 1:_nstate
const stateid = (U = _U, h = _h)

const _nvgeo = 4
const _ξx, _MJ, _MJI, _x = 1:_nvgeo

const _nsgeo = 3
const _nx, _sMJ, _vMJI = 1:_nsgeo</code></pre><pre><code class="language-none">1:3</code></pre></div><p>}}}</p><p>{{{ cfl</p><div><pre><code class="language-julia">function cfl(::Val{dim}, ::Val{N}, vgeo, Q, mpicomm) where {dim, N}
    DFloat = eltype(Q)
    Np = (N+1)^dim
    (~, ~, nelem) = size(Q)
    dt = [floatmax(DFloat)]
    Courant = - [floatmax(DFloat)]

    #Compute DT
    @inbounds for e = 1:nelem, n = 1:Np
        U = Q[n, _U, e]
        ξx = vgeo[n, _ξx, e]
        dx=1.0/(2*ξx)
        wave_speed = abs(U)
        loc_dt = 0.25*dx/wave_speed/N
        dt[1] = min(dt[1], loc_dt)
    end
    dt_min=MPI.Allreduce(dt[1], MPI.MIN, mpicomm)

    #Compute Courant
    @inbounds for e = 1:nelem, n = 1:Np
        U = Q[n, _U, e]
        ξx = vgeo[n, _ξx, e]
        dx=1.0/(2*ξx)
        wave_speed = abs(U)
        loc_Courant = wave_speed*dt[1]/dx*N
        Courant[1] = max(Courant[1], loc_Courant)
    end
    Courant_max=MPI.Allreduce(Courant[1], MPI.MAX, mpicomm)

    (dt_min, Courant_max)
end</code></pre><pre><code class="language-none">cfl (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ compute geometry</p><div><pre><code class="language-julia">function computegeometry(::Val{dim}, mesh, D, ξ, ω, meshwarp, vmapM) where dim</code></pre></div><p>Compute metric terms</p><div><pre><code class="language-julia">    Nq = size(D, 1)
    DFloat = eltype(D)

    (nface, nelem) = size(mesh.elemtoelem)

    crd = creategrid(Val(dim), mesh.elemtocoord, ξ)

    vgeo = zeros(DFloat, Nq^dim, _nvgeo, nelem)
    sgeo = zeros(DFloat, _nsgeo, Nq^(dim-1), nface, nelem)

    (ξx, MJ, MJI, x) = ntuple(j-&gt;(@view vgeo[:, j, :]), _nvgeo)
    J = similar(x)
    (nx, sMJ, vMJI) = ntuple(j-&gt;(@view sgeo[ j, :, :, :]), _nsgeo)
    sJ = similar(sMJ)

    X = ntuple(j-&gt;(@view vgeo[:, _x+j-1, :]), dim)
    creategrid!(X..., mesh.elemtocoord, ξ)

    @inbounds for j = 1:length(x)</code></pre></div><p>(x[j]) = meshwarp(x[j],)</p><div><pre><code class="language-julia">    end</code></pre></div><p>Compute the metric terms</p><div><pre><code class="language-julia">    computemetric!(x, J, ξx, sJ, nx, D)

    M = kron(1, ntuple(j-&gt;ω, dim)...)
    MJ .= M .* J
    MJI .= 1 ./ MJ
    vMJI .= MJI[vmapM]

    sM = dim &gt; 1 ? kron(1, ntuple(j-&gt;ω, dim-1)...) : one(DFloat)
    sMJ .= sM .* sJ

    (vgeo, sgeo)
end</code></pre><pre><code class="language-none">computegeometry (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ CPU Kernels {{{ Volume RHS for 1D</p><div><pre><code class="language-julia">function volumerhs!(::Val{1}, ::Val{N}, rhs::Array, Q, vgeo, D, elems) where N
    DFloat = eltype(Q)
    Nq = N + 1
    nelem = size(Q)[end]

    Q = reshape(Q, Nq, _nstate, nelem)
    rhs = reshape(rhs, Nq, _nstate, nelem)
    vgeo = reshape(vgeo, Nq, _nvgeo, nelem)

    #Allocate Arrays
    s_F = Array{DFloat}(undef, Nq, _nstate)

    @inbounds for e in elems
        for i = 1:Nq
            MJ, ξx = vgeo[i,_MJ,e], vgeo[i,_ξx,e]
            U = Q[i, _U, e]

            #Get primitive variables
            U=U

            #Compute fluxes
            fluxU_x = 0.5*U^2
            s_F[i, _U] = MJ * (ξx * fluxU_x)
        end</code></pre></div><p>loop of ξ-grid lines</p><div><pre><code class="language-julia">        for s = 1:_nstate, i = 1:Nq, k = 1:Nq
            rhs[i, s, e] += D[k, i] * s_F[k, s]
        end
    end
end</code></pre><pre><code class="language-none">volumerhs! (generic function with 1 method)</code></pre></div><p>}}}</p><p>Flux RHS for 1D</p><div><pre><code class="language-julia">function fluxrhs!(::Val{1}, ::Val{N}, rhs::Array,  Q, sgeo, elems, vmapM, vmapP, elemtobndy) where N
    DFloat = eltype(Q)
    Np = (N+1)
    Nfp = 1
    nface = 2

    @inbounds for e in elems
        for f = 1:nface
            for n = 1:Nfp
                nxM, sMJ = sgeo[_nx, n, f, e], sgeo[_sMJ, n, f, e]
                idM, idP = vmapM[n, f, e], vmapP[n, f, e]

                eM, eP = e, ((idP - 1) ÷ Np) + 1
                vidM, vidP = ((idM - 1) % Np) + 1,  ((idP - 1) % Np) + 1

                UM = Q[vidM, _U, eM]
                bc = elemtobndy[f, e]
                UP = zero(eltype(Q))
                if bc == 0
                    UP = Q[vidP, _U, eP]
                elseif bc == 1
                    UnM = nxM * UM
                    UP = UM - 2 * UnM * nxM
                else
                    error(&quot;Invalid boundary conditions $bc on face $f of element $e&quot;)
                end

                #Left Fluxes
                fluxUM_x = 0.5*UM^2

                #Right Fluxes
                fluxUP_x = 0.5*UP^2

                #Compute wave speed
                λM=abs(nxM * UM)
                λP=abs(nxM * UP)
                λ = max( λM, λP )

                #Compute Numerical/Rusanov Flux
                fluxUS = (nxM * (fluxUM_x + fluxUP_x) - λ * (UP - UM)) / 2

                #Update RHS
                rhs[vidM, _U, eM] -= sMJ * fluxUS
            end
        end
    end
end</code></pre><pre><code class="language-none">fluxrhs! (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ Volume Q</p><div><pre><code class="language-julia">function volumeQ!(::Val{1}, ::Val{N}, rhs::Array, Q, vgeo, D, elems) where N
    DFloat = eltype(Q)
    Nq = N + 1
    nelem = size(Q)[end]

    Q = reshape(Q, Nq, _nstate, nelem)
    rhs = reshape(rhs, Nq, _nstate, nelem)
    vgeo = reshape(vgeo, Nq, _nvgeo, nelem)

    #Initialize RHS vector
    fill!( rhs, zero(rhs[1]))

    #Allocate Arrays
    s_F = Array{DFloat}(undef, Nq, _nstate)

    @inbounds for e in elems
        for i = 1:Nq
            MJ, ξx = vgeo[i,_MJ,e], vgeo[i,_ξx,e]
            U = Q[i, _U, e]

            #Get primitive variables
            U=U

            #Compute fluxes
            fluxU = U
            s_F[i, _U] = MJ * (ξx * fluxU)
        end</code></pre></div><p>loop of ξ-grid lines</p><div><pre><code class="language-julia">        for s = 1:_nstate, i = 1:Nq, k = 1:Nq
            rhs[i, s, e] -= D[k, i] * s_F[k, s]
        end
    end
end</code></pre><pre><code class="language-none">volumeQ! (generic function with 1 method)</code></pre></div><p>}}}</p><p>Flux Q</p><div><pre><code class="language-julia">function fluxQ!(::Val{1}, ::Val{N}, rhs::Array,  Q, sgeo, elems, vmapM, vmapP, elemtobndy) where N
    DFloat = eltype(Q)
    Np = (N+1)
    Nfp = 1
    nface = 2

    @inbounds for e in elems
        for f = 1:nface
            for n = 1:Nfp
                nxM, sMJ = sgeo[_nx, n, f, e], sgeo[_sMJ, n, f, e]
                idM, idP = vmapM[n, f, e], vmapP[n, f, e]

                eM, eP = e, ((idP - 1) ÷ Np) + 1
                vidM, vidP = ((idM - 1) % Np) + 1,  ((idP - 1) % Np) + 1

                UM = Q[vidM, _U, eM]
                bc = elemtobndy[f, e]
                UP = zero(eltype(Q))
                if bc == 0
                    UP = Q[vidP, _U, eP]
                elseif bc == 1
                    UnM = nxM * UM
                    UP = UM - 2 * UnM * nxM
                else
                    error(&quot;Invalid boundary conditions $bc on face $f of element $e&quot;)
                end

                #Left Fluxes
                fluxUM = UM

                #Right Fluxes
                fluxUP = UP

                #Compute Numerical/Rusanov Flux
                fluxUS = 0.5*(fluxUM + fluxUP)

                #Update RHS
                rhs[vidM, _U, eM] += sMJ * nxM * fluxUS
            end
        end
    end
end</code></pre><pre><code class="language-none">fluxQ! (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ Update solution</p><div><pre><code class="language-julia">function updatesolution!(::Val{dim}, ::Val{N}, rhs, rhs_gradQ, Q, vgeo, elems, rka, rkb, dt, visc) where {dim, N}

    DFloat = eltype(Q)
    Nq=(N+1)^dim
    (~, ~, nelem) = size(Q)

    @inbounds for e = elems, s = 1:_nstate, i = 1:Nq
        rhs[i, s, e] += visc*rhs_gradQ[i,s,e]
        Q[i, s, e] += rkb * dt * rhs[i, s, e] * vgeo[i, _MJI, e]
        rhs[i, s, e] *= rka
    end

end</code></pre><pre><code class="language-none">updatesolution! (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ Update grad Q solution</p><div><pre><code class="language-julia">function update_gradQ!(::Val{dim}, ::Val{N}, Q, rhs, vgeo, elems) where {dim, N}

    DFloat = eltype(Q)
    Nq=(N+1)^dim
    (~, ~, nelem) = size(Q)

    @inbounds for e = elems, s = 1:_nstate, i = 1:Nq
        Q[i, s, e] = rhs[i, s, e] * vgeo[i, _MJI, e] / π
    end

end</code></pre><pre><code class="language-none">update_gradQ! (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ GPU kernels {{{ Volume RHS for 1D</p><div><pre><code class="language-julia">@hascuda function knl_volumerhs!(::Val{1}, ::Val{N}, rhs, Q, vgeo, D, nelem) where N
    DFloat = eltype(D)
    Nq = N + 1

    #Point Thread to DOF and Block to element
    (i, j, k) = threadIdx()
    e = blockIdx().x

    #Allocate Arrays
    s_D = @cuStaticSharedMem(eltype(D), (Nq, Nq))
    s_F = @cuStaticSharedMem(eltype(Q), (Nq, _nstate))

    rhsU = rhsV = rhsh = zero(eltype(rhs))
    if i &lt;= Nq &amp;&amp; j == 1 &amp;&amp; k == 1 &amp;&amp; e &lt;= nelem</code></pre></div><p>Load derivative into shared memory</p><div><pre><code class="language-julia">        if k == 1
            s_D[i, j] = D[i, j]
        end</code></pre></div><p>Load values needed into registers</p><div><pre><code class="language-julia">        MJ = vgeo[i, j, _MJ, e]
        ξx = vgeo[i, j, _ξx, e]
        U = Q[i, _U, e]
        rhsU = rhs[i, _U, e]

        #Get primitive variables and fluxes
        U=U
        fluxU_x = 0.5*U^2
        s_F[i, _U] = MJ * (ξx * fluxU_x)
    end

    sync_threads()

    @inbounds if i &lt;= Nq &amp;&amp; j == 1 &amp;&amp; k == 1 &amp;&amp; e &lt;= nelem
        for n = 1:Nq
            #ξ-grid lines
            Dni = s_D[n, i]
            rhsU += Dni * s_F[n, _U]
        end
        rhs[i, _U, e] = rhsU
    end
    nothing
end</code></pre><pre><code class="language-none">()</code></pre></div><p>}}}</p><p>{{{ Face RHS (all dimensions)</p><div><pre><code class="language-julia">@hascuda function knl_fluxrhs!(::Val{dim}, ::Val{N}, rhs, Q, sgeo, nelem, vmapM, vmapP, elemtobndy) where {dim, N}
    DFloat = eltype(Q)
    Np = (N+1)^dim
    nface = 2*dim

    (i, j, k) = threadIdx()
    e = blockIdx().x

    Nq = N+1
    half = convert(eltype(Q), 0.5)

    @inbounds if i &lt;= Nq &amp;&amp; j == 1 &amp;&amp; k == 1 &amp;&amp; e &lt;= nelem
        n = i + (j-1) * Nq
        for lf = 1:2:nface
            for f = lf:lf+1
                nxM, sMJ = sgeo[_nx, n, f, e], sgeo[_sMJ, n, f, e]
                (idM, idP) = (vmapM[n, f, e], vmapP[n, f, e])

                (eM, eP) = (e, ((idP - 1) ÷ Np) + 1)
                (vidM, vidP) = (((idM - 1) % Np) + 1,  ((idP - 1) % Np) + 1)

                UM = Q[vidM, _U, eM]

                bc = elemtobndy[f, e]
                UP = zero(eltype(Q))
                if bc == 0
                    UP = Q[vidP, _U, eP]
                elseif bc == 1
                    UnM = nxM * UM
                    UP = UM - 2 * UnM * nxM</code></pre></div><pre><code class="language-none">         else
             error(&quot;Invalid boundary conditions $bc on face $f of element $e&quot;)</code></pre><div><pre><code class="language-julia">                end

                #Left Fluxes
                fluxUM_x = 0.5*UM^2

                #Right Fluxes
                fluxUP_x = 0.5*UP^2

                #Compute wave speed
                λM=abs(nxM * uM)
                λP=abs(nxM * uP)
                λ = max( λM, λP )

                #Compute Numerical Flux and Update
                fluxUS = (nxM * (fluxUM_x + fluxUP_x) - λ * (UP - UM)) / 2

                #Update RHS
                rhs[vidM, _U, eM] -= sMJ * fluxUS
            end
            sync_threads()
        end
    end
    nothing
end</code></pre><pre><code class="language-none">()</code></pre></div><p>}}}</p><p>{{{ Update solution (for all dimensions)</p><div><pre><code class="language-julia">@hascuda function knl_updatesolution!(::Val{dim}, ::Val{N}, rhs, Q, vgeo, nelem, rka, rkb, dt) where {dim, N}
    (i, j, k) = threadIdx()
    e = blockIdx().x

    Nq = N+1
    @inbounds if i &lt;= Nq &amp;&amp; j &lt;= Nq &amp;&amp; k &lt;= Nq &amp;&amp; e &lt;= nelem
        n = i + (j-1) * Nq + (k-1) * Nq * Nq
        MJI = vgeo[n, _MJI, e]
        for s = 1:_nstate
            Q[n, s, e] += rkb * dt * rhs[n, s, e] * MJI
            rhs[n, s, e] *= rka
        end
    end
    nothing
end</code></pre><pre><code class="language-none">()</code></pre></div><p>}}}</p><p>{{{ Fill sendQ on device with Q (for all dimensions)</p><div><pre><code class="language-julia">@hascuda function knl_fillsendQ!(::Val{dim}, ::Val{N}, sendQ, Q, sendelems) where {N, dim}
    Nq = N + 1
    (i, j, k) = threadIdx()
    e = blockIdx().x

    @inbounds if i &lt;= Nq &amp;&amp; j &lt;= Nq &amp;&amp; k &lt;= Nq &amp;&amp; e &lt;= length(sendelems)
        n = i + (j-1) * Nq + (k-1) * Nq * Nq
        re = sendelems[e]
        for s = 1:_nstate
            sendQ[n, s, e] = Q[n, s, re]
        end
    end
    nothing
end</code></pre><pre><code class="language-none">()</code></pre></div><p>}}}</p><p>{{{ Fill Q on device with recvQ (for all dimensions)</p><div><pre><code class="language-julia">@hascuda function knl_transferrecvQ!(::Val{dim}, ::Val{N}, Q, recvQ, nelem, nrealelem) where {N, dim}
    Nq = N + 1
    (i, j, k) = threadIdx()
    e = blockIdx().x

    @inbounds if i &lt;= Nq &amp;&amp; j &lt;= Nq &amp;&amp; k &lt;= Nq &amp;&amp; e &lt;= nelem
        n = i + (j-1) * Nq + (k-1) * Nq * Nq
        for s = 1:_nstate
            Q[n, s, nrealelem + e] = recvQ[n, s, e]
        end
    end
    nothing
end</code></pre><pre><code class="language-none">()</code></pre></div><p>}}}</p><p>{{{ MPI Buffer handling</p><div><pre><code class="language-julia">function fillsendQ!(::Val{dim}, ::Val{N}, sendQ, d_sendQ::Array, Q,
                    sendelems) where {dim, N}
    sendQ[:, :, :] .= Q[:, :, sendelems]
end

@hascuda function fillsendQ!(::Val{dim}, ::Val{N}, sendQ, d_sendQ::CuArray,
                             d_QL, d_sendelems) where {dim, N}
    nsendelem = length(d_sendelems)
    if nsendelem &gt; 0
        @cuda(threads=ntuple(j-&gt;N+1, dim), blocks=nsendelem,
              knl_fillsendQ!(Val(dim), Val(N), d_sendQ, d_QL, d_sendelems))
        sendQ .= d_sendQ
    end
end

@hascuda function transferrecvQ!(::Val{dim}, ::Val{N}, d_recvQ::CuArray, recvQ,
                                 d_QL, nrealelem) where {dim, N}
    nrecvelem = size(recvQ)[end]
    if nrecvelem &gt; 0
        d_recvQ .= recvQ
        @cuda(threads=ntuple(j-&gt;N+1, dim), blocks=nrecvelem,
              knl_transferrecvQ!(Val(dim), Val(N), d_QL, d_recvQ, nrecvelem,
                                 nrealelem))
    end
end

function transferrecvQ!(::Val{dim}, ::Val{N}, d_recvQ::Array, recvQ, Q,
                        nrealelem) where {dim, N}
    Q[:, :, nrealelem+1:end] .= recvQ[:, :, :]
end</code></pre><pre><code class="language-none">transferrecvQ! (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ GPU kernel wrappers</p><div><pre><code class="language-julia">@hascuda function volumerhs!(::Val{dim}, ::Val{N}, d_rhsC::CuArray, d_QC, d_vgeoC, d_D, elems) where {dim, N}
    nelem = length(elems)
    @cuda(threads=ntuple(j-&gt;N+1, dim), blocks=nelem,
          knl_volumerhs!(Val(dim), Val(N), d_rhsC, d_QC, d_vgeoC, d_D, nelem))
end

@hascuda function fluxrhs!(::Val{dim}, ::Val{N}, d_rhsL::CuArray, d_QL, d_sgeo, elems, d_vmapM, d_vmapP, d_elemtobndy) where {dim, N}
    nelem = length(elems)
    @cuda(threads=(ntuple(j-&gt;N+1, dim-1)..., 1), blocks=nelem,
          knl_fluxrhs!(Val(dim), Val(N), d_rhsL, d_QL, d_sgeo, nelem, d_vmapM, d_vmapP, d_elemtobndy))
end

@hascuda function updatesolution!(::Val{dim}, ::Val{N}, d_rhsL::CuArray, d_QL, d_vgeoL, elems, rka, rkb, dt) where {dim, N}
    nelem = length(elems)
    @cuda(threads=ntuple(j-&gt;N+1, dim), blocks=nelem,
          knl_updatesolution!(Val(dim), Val(N), d_rhsL, d_QL, d_vgeoL, nelem, rka, rkb, dt))
end</code></pre><pre><code class="language-none">()</code></pre></div><p>}}}</p><p>{{{ L2 Error (for all dimensions)</p><div><pre><code class="language-julia">function L2errorsquared(::Val{dim}, ::Val{N}, Q, vgeo, elems, Qex, t) where {dim, N}
    DFloat = eltype(Q)
    Np = (N+1)^dim
    (~, nstate, nelem) = size(Q)

    err = zero(DFloat)

    @inbounds for e = elems, i = 1:Np
        X = ntuple(j -&gt; vgeo[i, _x-1+j, e] - Q[i, _U-1+j, e]*t, Val(dim))
        diff = Q[i, _U, e] - Qex[i, _U, e]
        err += vgeo[i, _MJ, e] * diff^2
    end

    err
end</code></pre><pre><code class="language-none">L2errorsquared (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ L2 Energy (for all dimensions)</p><div><pre><code class="language-julia">function L2energysquared(::Val{dim}, ::Val{N}, Q, vgeo, elems) where {dim, N}
    DFloat = eltype(Q)
    Np = (N+1)^dim
    (~, nstate, nelem) = size(Q)

    energy = zero(DFloat)

    @inbounds for e = elems, q = 1:nstate, i = 1:Np
        energy += vgeo[i, _MJ, e] * Q[i, q, e]^2
    end

    energy
end</code></pre><pre><code class="language-none">L2energysquared (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ Send Data</p><div><pre><code class="language-julia">function senddata(::Val{dim}, ::Val{N}, mesh, sendreq, recvreq, sendQ,
                  recvQ, d_sendelems, d_sendQ, d_recvQ, d_QL, mpicomm;
                  ArrType=ArrType) where {dim, N}
    DFloat = eltype(d_QL)
    mpirank = MPI.Comm_rank(mpicomm)</code></pre></div><p>Create send and recv request array</p><div><pre><code class="language-julia">    nnabr = length(mesh.nabrtorank)
    d_sendelems = ArrType(mesh.sendelems)
    nrealelem = length(mesh.realelems)</code></pre></div><p>post MPI receives</p><div><pre><code class="language-julia">    for n = 1:nnabr
        recvreq[n] = MPI.Irecv!((@view recvQ[:, :, mesh.nabrtorecv[n]]),
                                mesh.nabrtorank[n], 777, mpicomm)
    end</code></pre></div><p>wait on (prior) MPI sends</p><div><pre><code class="language-julia">    MPI.Waitall!(sendreq)</code></pre></div><p>pack data from d_QL into send buffer</p><div><pre><code class="language-julia">    fillsendQ!(Val(dim), Val(N), sendQ, d_sendQ, d_QL, d_sendelems)</code></pre></div><p>post MPI sends</p><div><pre><code class="language-julia">    for n = 1:nnabr
        sendreq[n] = MPI.Isend((@view sendQ[:, :, mesh.nabrtosend[n]]),
                               mesh.nabrtorank[n], 777, mpicomm)
    end
end</code></pre><pre><code class="language-none">senddata (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ Receive Data</p><div><pre><code class="language-julia">function receivedata!(::Val{dim}, ::Val{N}, mesh, recvreq,
                      recvQ, d_recvQ, d_QL) where {dim, N}
    DFloat = eltype(d_QL)
    nrealelem = length(mesh.realelems)</code></pre></div><p>wait on MPI receives</p><div><pre><code class="language-julia">    MPI.Waitall!(recvreq)</code></pre></div><p>copy data to state vector d_QL</p><div><pre><code class="language-julia">    transferrecvQ!(Val(dim), Val(N), d_recvQ, recvQ, d_QL, nrealelem)

end</code></pre><pre><code class="language-none">receivedata! (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ RK loop</p><div><pre><code class="language-julia">function lowstorageRK(::Val{dim}, ::Val{N}, mesh, vgeo, sgeo, Q, rhs, D,
                      dt, nsteps, tout, vmapM, vmapP, mpicomm, visc;
                      ArrType=ArrType, plotstep=0) where {dim, N}
    DFloat = eltype(Q)
    mpirank = MPI.Comm_rank(mpicomm)</code></pre></div><p>Fourth-order, low-storage, Runge–Kutta scheme of Carpenter and Kennedy (1994) ((5,4) 2N-Storage RK scheme.</p><p>Ref: @TECHREPORT{CarpenterKennedy1994,   author = {M.~H. Carpenter and C.~A. Kennedy},   title = {Fourth-order {2N-storage} {Runge-Kutta} schemes},   institution = {National Aeronautics and Space Administration},   year = {1994},   number = {NASA TM-109112},   address = {Langley Research Center, Hampton, VA}, }</p><div><pre><code class="language-julia">    RKA = (DFloat(0),
           DFloat(-567301805773)  / DFloat(1357537059087),
           DFloat(-2404267990393) / DFloat(2016746695238),
           DFloat(-3550918686646) / DFloat(2091501179385),
           DFloat(-1275806237668) / DFloat(842570457699 ))

    RKB = (DFloat(1432997174477) / DFloat(9575080441755 ),
           DFloat(5161836677717) / DFloat(13612068292357),
           DFloat(1720146321549) / DFloat(2090206949498 ),
           DFloat(3134564353537) / DFloat(4481467310338 ),
           DFloat(2277821191437) / DFloat(14882151754819))

    RKC = (DFloat(0),
           DFloat(1432997174477) / DFloat(9575080441755),
           DFloat(2526269341429) / DFloat(6820363962896),
           DFloat(2006345519317) / DFloat(3224310063776),
           DFloat(2802321613138) / DFloat(2924317926251))</code></pre></div><p>Create send and recv request array</p><div><pre><code class="language-julia">    nnabr = length(mesh.nabrtorank)
    sendreq = fill(MPI.REQUEST_NULL, nnabr)
    recvreq = fill(MPI.REQUEST_NULL, nnabr)</code></pre></div><p>Create send and recv buffer</p><div><pre><code class="language-julia">    sendQ = zeros(DFloat, (N+1)^dim, size(Q,2), length(mesh.sendelems))
    recvQ = zeros(DFloat, (N+1)^dim, size(Q,2), length(mesh.ghostelems))

    nrealelem = length(mesh.realelems)
    nsendelem = length(mesh.sendelems)
    nrecvelem = length(mesh.ghostelems)
    nelem = length(mesh.elems)

    d_QL, d_rhsL = ArrType(Q), ArrType(rhs)
    d_vgeoL, d_sgeo = ArrType(vgeo), ArrType(sgeo)
    d_vmapM, d_vmapP = ArrType(vmapM), ArrType(vmapP)
    d_sendelems, d_elemtobndy = ArrType(mesh.sendelems), ArrType(mesh.elemtobndy)
    d_sendQ, d_recvQ = ArrType(sendQ), ArrType(recvQ)
    d_D = ArrType(D)
    d_gradQL = ArrType(Q)
    d_rhs_gradQL = ArrType(rhs)

    Qshape    = (fill(N+1, dim)..., size(Q, 2), size(Q, 3))
    vgeoshape = (fill(N+1, dim)..., _nvgeo, size(Q, 3))

    d_QC = reshape(d_QL, Qshape)
    d_rhsC = reshape(d_rhsL, Qshape...)
    d_vgeoC = reshape(d_vgeoL, vgeoshape)
    d_gradQC = reshape(d_gradQL, Qshape)
    d_rhs_gradQC = reshape(d_rhs_gradQL, Qshape)</code></pre></div><p>Send Data</p><div><pre><code class="language-julia">    senddata(Val(dim), Val(N), mesh, sendreq, recvreq, sendQ,
             recvQ, d_sendelems, d_sendQ, d_recvQ, d_QL, mpicomm;
             ArrType=ArrType)</code></pre></div><p>Receive Data</p><div><pre><code class="language-julia">    receivedata!(Val(dim), Val(N), mesh, recvreq, recvQ, d_recvQ, d_QL)</code></pre></div><p>volume Q computation</p><div><pre><code class="language-julia">    volumeQ!(Val(dim), Val(N), d_rhs_gradQC, d_QC, d_vgeoC, d_D, mesh.realelems)</code></pre></div><p>face Q computation</p><div><pre><code class="language-julia">    fluxQ!(Val(dim), Val(N), d_rhs_gradQL, d_QL, d_sgeo, mesh.realelems, d_vmapM, d_vmapP, d_elemtobndy)</code></pre></div><p>Construct grad Q</p><div><pre><code class="language-julia">    update_gradQ!(Val(dim), Val(N), d_gradQL, d_rhs_gradQL, d_vgeoL, mesh.realelems)</code></pre></div><p>Send Data</p><div><pre><code class="language-julia">    senddata(Val(dim), Val(N), mesh, sendreq, recvreq, sendQ,
             recvQ, d_sendelems, d_sendQ, d_recvQ, d_gradQL,
             mpicomm;ArrType=ArrType)</code></pre></div><p>volume grad Q computation</p><div><pre><code class="language-julia">    volumeQ!(Val(dim), Val(N), d_rhs_gradQC, d_gradQC, d_vgeoC, d_D, mesh.realelems)</code></pre></div><p>Receive Data</p><div><pre><code class="language-julia">    receivedata!(Val(dim), Val(N), mesh, recvreq, recvQ, d_recvQ, d_gradQL)</code></pre></div><p>face grad Q computation</p><div><pre><code class="language-julia">    fluxQ!(Val(dim), Val(N), d_rhs_gradQL, d_gradQL, d_sgeo, mesh.realelems, d_vmapM, d_vmapP, d_elemtobndy)</code></pre></div><p>Construct grad Q</p><div><pre><code class="language-julia">    update_gradQ!(Val(dim), Val(N), d_QL, d_rhs_gradQL, d_vgeoL, mesh.realelems)
    Q .= d_QL
    rhs .= d_rhsL
end</code></pre><pre><code class="language-none">lowstorageRK (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ LDG driver</p><div><pre><code class="language-julia">function LDG(::Val{dim}, ::Val{N}, mpicomm, ic, mesh, tend, visc;
             meshwarp=(x...)-&gt;identity(x), tout = 60, ArrType=Array,
             plotstep=0) where {dim, N}
    DFloat = typeof(tend)

    mpirank = MPI.Comm_rank(mpicomm)
    mpisize = MPI.Comm_size(mpicomm)</code></pre></div><p>Partion the mesh using a Hilbert curve based partitioning</p><div><pre><code class="language-julia">    mpirank == 0 &amp;&amp; println(&quot;[CPU] partitioning mesh...&quot;)
    mesh = partition(mpicomm, mesh...)</code></pre></div><p>Connect the mesh in parallel</p><div><pre><code class="language-julia">    mpirank == 0 &amp;&amp; println(&quot;[CPU] connecting mesh...&quot;)
    mesh = connectmesh(mpicomm, mesh...)</code></pre></div><p>Get the vmaps</p><div><pre><code class="language-julia">    mpirank == 0 &amp;&amp; println(&quot;[CPU] computing mappings...&quot;)
    (vmapM, vmapP) = mappings(N, mesh.elemtoelem, mesh.elemtoface,
                              mesh.elemtoordr)</code></pre></div><p>Create 1-D operators</p><div><pre><code class="language-julia">    (ξ, ω) = lglpoints(DFloat, N)
    D = spectralderivative(ξ)</code></pre></div><p>Compute the geometry</p><div><pre><code class="language-julia">    mpirank == 0 &amp;&amp; println(&quot;[CPU] computing metrics...&quot;)
    (vgeo, sgeo) = computegeometry(Val(dim), mesh, D, ξ, ω, meshwarp, vmapM)
    (nface, nelem) = size(mesh.elemtoelem)</code></pre></div><p>Storage for the solution, rhs, and error</p><div><pre><code class="language-julia">    mpirank == 0 &amp;&amp; println(&quot;[CPU] creating fields (CPU)...&quot;)
    Q = zeros(DFloat, (N+1)^dim, _nstate, nelem)
    Qexact = zeros(DFloat, (N+1)^dim, _nstate, nelem)
    rhs = zeros(DFloat, (N+1)^dim, _nstate, nelem)</code></pre></div><p>setup the initial condition</p><div><pre><code class="language-julia">    mpirank == 0 &amp;&amp; println(&quot;[CPU] computing initial conditions (CPU)...&quot;)
    @inbounds for e = 1:nelem, i = 1:(N+1)^dim
        x = vgeo[i, _x, e]
        (U, Uexact) = ic(x)
        Q[i, _U, e] = U
        Qexact[i, _U, e] = Uexact
    end</code></pre></div><p>Compute time step</p><div><pre><code class="language-julia">    mpirank == 0 &amp;&amp; println(&quot;[CPU] computing dt (CPU)...&quot;)
    (base_dt,Courant) = cfl(Val(dim), Val(N), vgeo, Q, mpicomm)
    base_dt=0.001  #FXG debug
    mpirank == 0 &amp;&amp; @show (base_dt,Courant)

    nsteps = ceil(Int64, tend / base_dt)
    dt = tend / nsteps
    mpirank == 0 &amp;&amp; @show (dt, nsteps, dt * nsteps, tend)</code></pre></div><p>Do time stepping</p><div><pre><code class="language-julia">    stats = zeros(DFloat, 3)
    mpirank == 0 &amp;&amp; println(&quot;[CPU] computing initial energy...&quot;)
    stats[1] = L2energysquared(Val(dim), Val(N), Q, vgeo, mesh.realelems)</code></pre></div><p>plot initial condition</p><div><pre><code class="language-julia">    mkpath(&quot;viz&quot;)
    X = ntuple(j-&gt;reshape((@view vgeo[:, _x+j-1, :]), ntuple(j-&gt;N+1,dim)...,
                          nelem), dim)
    U = reshape((@view Q[:, _U, :]), ntuple(j-&gt;(N+1),dim)..., nelem)
    writemesh(@sprintf(&quot;viz/LDG%dD_%s_rank_%04d_step_%05d&quot;,
                       dim, ArrType, mpirank, 0), X...;
              fields=((&quot;h&quot;, U),(&quot;U&quot;,U)),realelems=mesh.realelems)

    #Call Time-stepping Routine
    mpirank == 0 &amp;&amp; println(&quot;[DEV] starting time stepper...&quot;)
    lowstorageRK(Val(dim), Val(N), mesh, vgeo, sgeo, Q, rhs, D, dt, nsteps, tout,
                 vmapM, vmapP, mpicomm, visc;
                 ArrType=ArrType, plotstep=plotstep)</code></pre></div><p>plot final solution</p><div><pre><code class="language-julia">    X = ntuple(j-&gt;reshape((@view vgeo[:, _x+j-1, :]), ntuple(j-&gt;N+1,dim)...,
                          nelem), dim)
    U = reshape((@view Q[:, _U, :]), ntuple(j-&gt;(N+1),dim)..., nelem)
    writemesh(@sprintf(&quot;viz/LDG%dD_%s_rank_%04d_step_%05d&quot;,
                       dim, ArrType, mpirank, nsteps), X...;
              fields=((&quot;h&quot;, U),(&quot;U&quot;,U)),realelems=mesh.realelems)

    mpirank == 0 &amp;&amp; println(&quot;[CPU] computing final energy...&quot;)
    stats[2] = L2energysquared(Val(dim), Val(N), Q, vgeo, mesh.realelems)
    stats[3] = L2errorsquared(Val(dim), Val(N), Q, vgeo, mesh.realelems, Qexact,
                              tend)

    stats = sqrt.(MPI.allreduce(stats, MPI.SUM, mpicomm))

    if  mpirank == 0
        @show eng0 = stats[1]
        @show engf = stats[2]
        @show Δeng = engf - eng0
        @show err = stats[3]
    end
end</code></pre><pre><code class="language-none">LDG (generic function with 1 method)</code></pre></div><p>}}}</p><p>{{{ main</p><div><pre><code class="language-julia">function main()
    DFloat = Float64

    MPI.Initialized() || MPI.Init()
    MPI.finalize_atexit()

    mpicomm = MPI.COMM_WORLD
    mpirank = MPI.Comm_rank(mpicomm)
    mpisize = MPI.Comm_size(mpicomm)</code></pre></div><p>FIXME: query via hostname</p><div><pre><code class="language-julia">    @hascuda device!(mpirank % length(devices()))

    #Input Parameters
    N=4
    Ne=10
    visc=0.01
    iplot=10
    time_final=DFloat(1.0)
    hardware=&quot;cpu&quot;
    @show (N,Ne,visc,iplot,time_final,hardware)

    #Initial Conditions
    function ic(x...)
        U = sin( π*x[1] )
        Uexact = - sin( π*x[1] ) #2nd derivative
        (U, Uexact)
    end
    periodic = (true, )

    mesh = brickmesh((range(DFloat(0); length=Ne+1, stop=2),), periodic; part=mpirank+1, numparts=mpisize)

    if hardware == &quot;cpu&quot;
        mpirank == 0 &amp;&amp; println(&quot;Running (CPU)...&quot;)
        LDG(Val(1), Val(N), mpicomm, ic, mesh, time_final, visc;
            ArrType=Array, tout = 10, plotstep = iplot)
        mpirank == 0 &amp;&amp; println()
    elseif hardware == &quot;gpu&quot;
        @hascuda begin
            mpirank == 0 &amp;&amp; println(&quot;Running (GPU)...&quot;)
            LDG(Val(1), Val(N), mpicomm, ic, mesh, time_final, visc;
                ArrType=CuArray, tout = 10, plotstep = iplot)
            mpirank == 0 &amp;&amp; println()
        end
    end
    nothing
end</code></pre><pre><code class="language-none">main (generic function with 1 method)</code></pre></div><p>}}}</p><div><pre><code class="language-julia">main()</code></pre><pre><code class="language-none">(N, Ne, visc, iplot, time_final, hardware) = (4, 10, 0.01, 10, 1.0, &quot;cpu&quot;)
Running (CPU)...
[CPU] partitioning mesh...
[CPU] connecting mesh...
[CPU] computing mappings...
[CPU] computing metrics...
[CPU] creating fields (CPU)...
[CPU] computing initial conditions (CPU)...
[CPU] computing dt (CPU)...
(base_dt, Courant) = (0.001, 0.25)
(dt, nsteps, dt * nsteps, tend) = (0.001, 1000, 1.0, 1.0)
[CPU] computing initial energy...
[DEV] starting time stepper...
[CPU] computing final energy...
eng0 = stats[1] = 1.0000000000000004
engf = stats[2] = 1.0000004051173512
Δeng = engf - eng0 = 4.051173507768624e-7
err = stats[3] = 0.000900394327608629</code></pre></div><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../../../../manual/operators/"><span class="direction">Previous</span><span class="title">Element Operators</span></a><a class="next" href="../burger1d/"><span class="direction">Next</span><span class="title">1D Burgers Equation</span></a></footer></article></body></html>
